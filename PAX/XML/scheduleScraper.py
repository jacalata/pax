    #scrape event schedule
    schedule = soup.find('ul', attrs={'id': 'schedule'}) 
    days = schedule.findAll('li', recursive=False) #list of 3 days 
    for day in days:

        root = Element('xml')
        root.set('version', '1.0')
        if not SHORTMODE:
            root.append(Comment('Generated by ElementTree in webScraper.py at ' + generated_on))
            #makes life easier if we generate it without a timestamp for super basic testing
        schedule = SubElement(root, 'Schedule')
        
        dayName = day['id']
        dayDate = day.find('h2', recursive=True).text 
        if (True):
            print("############"+dayName)
        
        timeblocks=day.findAll('div', 'timeBlock')
        if SHORTMODE:
            timeblocks = [timeblocks[0]]
            
        for timeblock in timeblocks:
            
            events = timeblock.findAll('li',  recursive=True)
            if SHORTMODE:
                events = [events[0]]

            debugPrint(DEBUGMODE, "events html", events)
            
            # for each event, define name,kind,location,datetime,end,description
            for eventInfo in events:
                time.sleep(3)
                # time format is Sunday 9/2/2013 10:00 am
                eventTime = dayDate + "/" + str(year) + " " + timeblock.find('h3', 'time').text
                debugPrint(DEBUGMODE, "event time", eventTime)
                

                event = SubElement(schedule, 'Event')
                event.set('datetime', eventTime)
                debugPrint(DEBUGMODE, "event info", eventInfo)
                # to get more details, go through to the url
                detailUrl = eventInfo.find('a')['href']
                if (TESTLOCALLY):
                    debugPrintLabel(DEBUGMODE, "TestLocally")
                    detailUrl = detailUrl.rsplit('/', 1)[1]
                    detailUrl = os.path.join(offlinefolder, detailUrl + ".html")
                    detailPage = open(detailUrl, encoding=paxEncoding)
                else:
                    

                    headers = { 'User-Agent' : 'Mozilla/5.0' }
                    req = Request(detailUrl, None, headers);
                    detailSock = urlopen(req);
                    detailPage = detailSock.read()
                    debugPrint(DEBUGMODE, "detail url", detailUrl)
                    if DOWNLOAD:
                        saveBytesAsFile(detailPage,
                                    os.path.join(offlinefolder, detailUrl+".html"),
                                    DEBUGMODE)    
                detailSoup = BeautifulSoup(detailPage)
                eventDetail = detailSoup.find('div', 'white')
                
                eventName=eventDetail.find('h2').text
                debugPrint(DEBUGMODE, "Name = " + eventName)
                event.set('name', eventName)
                
                details = eventDetail.findAll('p')
                if (len(details) == 0):
                    eventDescription = ""
                else:
                     eventDescription = details[0].text
                if eventDetail.find('h4') is not None:
                    eventDescription = eventDescription + " -- " + eventDetail.find('h4').text + " " + details[1].text
                debugPrint(DEBUGMODE, "description = " + eventDescription)
                event.set('description', eventDescription)

                options = eventDetail.find('ul', 'meta')
                debugPrint(DEBUGMODE, "details = " + options.text)
                if (options.find('li', 'con')):
                    endTimeIndex = 2 # concert info gets shoehorned in front of the datetime info
                    print("CON")
                else:
                    endTimeIndex = 1
                endTimeText = options.findAll('li', recursive=True)[endTimeIndex].text#eeewwww 
                debugPrint(DEBUGMODE, "end time text", endTimeText)
                endTime = endTimeText.split()[4]
                debugPrint(DEBUGMODE, "end time value", endTime)
                # need to go from 1:30AM to 1.30 AM
                endTime = endTime.replace("AM", " AM")
                endTime = endTime.replace("PM", " PM")

                eventEnd = str(dayDate) + "/" + str(year) + " " + str(endTime)
                debugPrint(DEBUGMODE, "end = " + eventEnd)
                event.set('end', eventEnd)

                eventLocation = options.find('a', recursive=True).text
                debugPrint(DEBUGMODE, "location= " + eventLocation)
                event.set('location', eventLocation)

                if eventLocation not in Locations:
                    Locations.append(eventLocation)
                
                eventKind="Panel" #default assumption. Special cases:
                if 'Concerts' in eventName:
                    eventKind = "Show"
                elif ('Tournament' in eventLocation)  or ('Tournament' in eventName):
                    eventKind = "Contest"
                elif 'Omegathon' in eventName:
                    eventKind = "Omegathon"
                debugPrint(DEBUGMODE, "kind = " + eventKind)
                event.set('kind', eventKind)

                if eventKind not in Kinds:
                    Kinds.append(eventKind)

        dayData = tostring(root).decode('utf-8')
        debugPrint(DEBUGMODE, "day xml", dayData)
        saveStringAsFile(dayData, outputfolder+"\\"+dayName+".xml", DEBUGMODE)


        fileDetail = SubElement(filesInfo, 'file')
        fileDetail.set('type', 'xml')
        fileDetail.set('name', dayName + ".xml");      

    #end for day in days


    print("schedule scraper done")
    return root
