#PAX7 script for scraping the web schedule and turning it into an xml doc

from urllib.request import urlopen
from bs4 import BeautifulSoup
from xml.etree.ElementTree import Element, SubElement, Comment, tostring
import datetime
import sys
import getopt
import os
import string #for clearing weird characters out of strings for filenames
import re #regexp

osPath = os.path.dirname(__file__)
generated_on = str(datetime.datetime.now())
year = "2012" #doesn't get specified, I guess they expect you to know what year it is
paxEncoding = "utf-8" #is waht the pax site says they use


# pull the metadata straight out of the schedule where possible
Locations = []
Kinds = [] #"Tabletop", "Panel", "Show", "Contest", "Omegathon", "FreePlay", "D&D", "Social"]

def usage():
    print("open a command line and call python webScraper.py.")
    print("arguments:")
    print("d / --debug: include basic logging")
    print("l / --local: test without hitting the server. Must provide local input")
    print("s / --short: parse only the first event of each day, speed up test cycle")
    print("v / --verbose: spew verbose logs for debugging")

import string

class Del:
  def __init__(self, keep=string.ascii_letters):
    self.comp = dict((ord(c),c) for c in keep)
  def __getitem__(self, k):
    return self.comp.get(k)

DD = Del()


#extract file saving code, it gets used a lot in this
#data is the (string) data to save in the file
#filename is the filename to save it as
#extension is usually either html or xml
def saveStringAsFile(data, filename):
    safeFilename = filename.translate(DD)
    print(safeFilename)
    fileWriter = open(safeFilename, 'w', encoding=paxEncoding)
    print(type(data))
    fileWriter.write(data)
    fileWriter.close()

def saveBytesAsFile(data, filename):
    safeFilename = filename.translate(DD)
    print(safeFilename)
    fileWriter = open(safeFilename, 'w', encoding=paxEncoding)
    print(type(data))
    fileWriter.write(data.decode())
    fileWriter.close()

def saveTextIOAsFile(data, filename):
    safeFilename = filename.translate(DD)
    print(safeFilename)
    fileWriter = open(safeFilename, 'w')
    print(type(data))
    fileWriter.write(data.read())
    fileWriter.close()

def main(argv):
    print ("Arguments")
    print (argv)
    print("---------------------------------------------------")

    # set defaults
    TESTLOCALLY = False
    SHORTMODE = False
    DEBUGMODE = False
    DEBUGPRINT = False
    sampledatafolder = os.path.join(osPath,"eccc\sampledata")    
    offlinefolder =  os.path.join(osPath, "eccc")
    print(sampledatafolder)

    try:                                
        opts, args = getopt.getopt(argv, "dhlsv:", ["debug", "help", "local", "short", "verbose"])
    except getopt.GetoptError:          
        usage()                         
        sys.exit(2)
    for opt, arg in opts:               
        if opt in ("-d", "--debug"):
            DEBUGMODE = True
        elif opt in ("-h", "--help"):
            usage()
            sys.exit()
        elif opt in ("-l", "--local"):
            TESTLOCALLY = True    
        elif opt in ("-s", "--short"):
            SHORTMODE = True
        elif opt in ("-v", "--verbose"):
            DEBUGPRINT = True
    print ("Debug, Local, Short, Verbose = ", DEBUGMODE, TESTLOCALLY, SHORTMODE, DEBUGPRINT)               

    
    if (TESTLOCALLY):
        if (DEBUGMODE):
            print("TestLocally")
        pageLocation = sampledatafolder+"\schedule.htm"
        page = open(pageLocation, encoding='utf-8')
    else:
        url = "http://www.emeraldcitycomicon.com/programming/" #"http://prime.paxsite.com/schedule"
        if (DEBUGMODE):
            print("url:" + url)
        sock = urlopen(url)
        page = sock.read() #returns a bytes object
        #save the page for offline work or debugging
        saveBytesAsFile(page, offlinefolder+"\Schedule.html");
        sock.close()

    soup = BeautifulSoup(page)
    schedule = soup.findAll('h2', 'tac green b_mar_twenty')
    print(len(schedule))

    for day in schedule:
        print(day.text)
        
        root = Element('xml')
        root.set('version', '1.0')
        if not SHORTMODE:
            root.append(Comment('Generated by ElementTree in webScraper.py at ' + generated_on))
            #makes life easier if we generate it without a timestamp for super basic testing
        schedule = SubElement(root, 'Schedule')
        
        dayName, dayDate = (day.text).split(',')
        #dayDate = day.find('h2', recursive=True).text 
        if (DEBUGMODE):
            print("############"+dayName)
            print("############"+dayDate)

        #find sibling div with class=programming_table
        eventDiv = day.findNextSibling('div', 'programming_table')
                
        events = eventDiv.findAll('a', 'pop programming_event')
    #set of events
        if True: #DEBUGMODE:
            events = [events[0]]

        if True: #(DEBUGPRINT):
            print(events)
            
        # the shitty broken html they have with <span><em></span></em>
        # means it will be easier to extract everything from the details page
   
        # for each event, define name,kind,location,datetime,end,description
        for eventInfo in events:

            event = SubElement(schedule, 'Event')


            if DEBUGPRINT:
                print(eventInfo)

            # to get more details, go through to the url
            detailUrl = eventInfo['href']

            if (TESTLOCALLY):
                if DEBUGMODE:
                    print("TestLocally")
                detailUrl = detailUrl.rsplit('/', 1)[1]
                detailUrl = os.path.join(offlinefolder, detailUrl + ".html")
                detailPage = open(detailUrl, encoding=paxEncoding)
            else:
                detailSock = urlopen(detailUrl)
                detailPage = detailSock.read()
                if DEBUGPRINT:
                    print(detailUrl)
                saveBytesAsFile(detailPage,
                                os.path.join(offlinefolder, detailUrl+".html"))    

            #read details from the small standalone page
            detailSoup = BeautifulSoup(detailPage)
        

            eventName = detailSoup.find('h1').text
            if DEBUGPRINT:
                print("Name = " + eventName)
            event.set('name', eventName)

            eventDescription = detailSoup.find('p', 'rte').text
            if DEBUGPRINT:
                print("description = " + eventDescription)
            event.set('description', eventDescription)
      	
            eventKind="Panel"  #(should get rid of this)
            event.set('kind', eventKind)

            eventLocation = detailSoup.find('strong').text.split(' ')[1]        
            if DEBUGPRINT:
                print("location = " + eventLocation)
            event.set('location', eventLocation)

            if eventLocation not in Locations:
                Locations.append(eventLocation)

            #start, end
            #<em><br/>Start: 11:00AM<br/>End: 11:55AM</em>
            eventTimes = detailSoup.find('em').text.replace("End: ", " ")
            (blah, startTime, endTime) = eventTimes.split(' ')
            if DEBUGPRINT:
                print("start = " + startTime)
                print("end = " + endTime)
            event.set('start', startTime)
            event.set('end', endTime)
           

        xml_string = tostring(root).decode('utf-8')
        if DEBUGMODE or DEBUGPRINT:
            print(xml_string)

        saveStringAsFile(xml_string, osPath+"\\"+dayName+".xml")

def printing():
    # print xml schema showing locations and kinds of events
    root = Element('xml')
    root.set('version', '1.0')
    root.append(Comment('Generated by ElementTree in webScraper.py at ' + generated_on))

    xml_locations = SubElement(root, 'Locations')
    for name in Locations:
        location = SubElement(xml_locations, 'location')
        location.set('name', name)

    xml_kinds = SubElement(root, 'Kinds')
    for name in Kinds:
        kind = SubElement(xml_kinds, 'kind')
        kind.set('name', name)

    xml_string = tostring(root).decode('utf-8')
    if DEBUGMODE or DEBUGPRINT:
        print(xml_string)

    saveAsFile(xml_string, osPath+"\ScheduleValues.xml")
    print("done")

        
if __name__ == "__main__":
    main(sys.argv[1:])

